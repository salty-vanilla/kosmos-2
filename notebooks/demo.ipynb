{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakatsuka/.cache/pypoetry/virtualenvs/kosmos-2-LcC9r1mE-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from argparse import Namespace\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from fairseq_cli.generate import get_symbols_to_strip_from_output\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from fairseq import checkpoint_utils, distributed_utils, options, tasks, utils\n",
    "from fairseq.dataclass.configs import FairseqConfig\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
    "from fairseq.token_generation_constraints import pack_constraints, unpack_constraints\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple(\"Batch\", \"ids src_tokens src_lengths constraints img_src_tokens img_gpt_input_mask img_path_batch\")\n",
    "Translation = namedtuple(\"Translation\", \"src_str hypos pos_scores alignments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=os.environ.get(\"LOGLEVEL\", \"INFO\").upper(),\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "logger = logging.getLogger(\"fairseq_cli.interactive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_transform(size=224):\n",
    "    inception_normalize = transforms.Compose(\n",
    "        [transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])]\n",
    "    )\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((size, size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            inception_normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def split_string(string, separators):\n",
    "    \"\"\"\n",
    "    Function to split a given string based on a list of separators.\n",
    "\n",
    "    Args:\n",
    "    string (str): The input string to be split.\n",
    "    separators (list): A list of separators to be used for splitting the string.\n",
    "\n",
    "    Returns:\n",
    "    A list containing the split string with separators included.\n",
    "    \"\"\"\n",
    "    pattern = \"|\".join(re.escape(separator) for separator in separators) \n",
    "    result = re.split(f'({pattern})', string)  \n",
    "    return [elem for elem in result if elem] \n",
    "\n",
    "def get_interactive_tokens_and_lengths(self, lines, encode_fn, tokenizer=None):\n",
    "    \"\"\"\n",
    "    line format: [image]path<tab>text<tab>[image]path\n",
    "    model input: `<s> <image> image hidden </image> My cat looking very dignified.</s>`\n",
    "    \"\"\"\n",
    "    image_feature_length = self.args.image_feature_length\n",
    "    bos_id = self.dictionary.bos()\n",
    "    eos_id = self.dictionary.eos()\n",
    "    boi_id = self.dictionary.index(\"<image>\")\n",
    "    eoi_id = self.dictionary.index(\"</image>\")\n",
    "    \n",
    "    def convert_one_line(input_str):\n",
    "        # TODO: input interleave image and text\n",
    "        token = []\n",
    "        img_src_token = []\n",
    "        img_gpt_input_mask = []\n",
    "        segments = input_str.split('<tab>')\n",
    "        token.append(bos_id)\n",
    "        img_gpt_input_mask.append(0)\n",
    "        for i, segment in enumerate(segments):\n",
    "            if segment.startswith('[image]'):\n",
    "                image_path = segment[7:]\n",
    "                # read image and transform to tensor\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                # update the global_path\n",
    "                # global global_image_path\n",
    "                # global_image_path = image_path\n",
    "                image_tensor = square_transform(self.args.input_resolution)(image)\n",
    "                img_src_token.append(image_tensor)\n",
    "                # global global_image_tensor\n",
    "                # global_image_tensor = image_tensor\n",
    "                token.extend([boi_id] + list(range(4, image_feature_length+4)) + [eoi_id])\n",
    "                \n",
    "                img_gpt_input_mask.extend([0] + [1] * image_feature_length + [0])\n",
    "            else:\n",
    "                special_tokens = [self.source_dictionary[idx] for idx in range(tokenizer.vocab_size(), \n",
    "                                                                               len(self.source_dictionary))]\n",
    "                split_special_token_words = []\n",
    "                split_resutls = split_string(segment, special_tokens)\n",
    "                for string in split_resutls:\n",
    "                    if string in special_tokens:\n",
    "                        # print(f\"dict-length({len(self.source_dictionary)}), substring {string} is a special token\")\n",
    "                        split_special_token_words.append(string)\n",
    "                    else:\n",
    "                        encode_tokens = tokenizer.encode(string, out_type=str)\n",
    "                        # print(f\"dict-length({len(self.source_dictionary)}), substring {string} is not a special token, tokenized into {encode_tokens}\")\n",
    "                        split_special_token_words.extend(encode_tokens)\n",
    "                segment = ' '.join(split_special_token_words)\n",
    "                \n",
    "                text_tokens = self.source_dictionary.encode_line(\n",
    "                    encode_fn(segment), add_if_not_exist=False\n",
    "                ).tolist()\n",
    "                \n",
    "                text_tokens = text_tokens[:-1] # </s> in token\n",
    "                token.extend(text_tokens)\n",
    "                img_gpt_input_mask.extend([0] * (len(text_tokens))) # </s> in token\n",
    "        token.append(eos_id)\n",
    "        # img_gpt_input_mask = img_gpt_input_mask[:-1]\n",
    "        assert len(token) == len(img_gpt_input_mask) + 1 \n",
    "        token = torch.LongTensor(token)\n",
    "        img_gpt_input_mask = torch.LongTensor(img_gpt_input_mask)\n",
    "        img_src_token = torch.stack(img_src_token, dim=0)\n",
    "        return token, img_src_token, img_gpt_input_mask\n",
    "    \n",
    "    tokens = []\n",
    "    img_src_tokens = []\n",
    "    img_gpt_input_masks = []\n",
    "    for src_str in lines:\n",
    "        token, img_src_token, img_gpt_input_mask = convert_one_line(src_str)\n",
    "        tokens.append(token)\n",
    "        img_src_tokens.append(img_src_token)\n",
    "        img_gpt_input_masks.append(img_gpt_input_mask)\n",
    "    lengths = [t.numel() for t in tokens]\n",
    "    \n",
    "    return tokens, lengths, img_src_tokens, img_gpt_input_masks\n",
    "\n",
    "\n",
    "def make_batches(lines, cfg, task, max_positions, encode_fn):\n",
    "    def encode_fn_target(x):\n",
    "        return encode_fn(x)\n",
    "\n",
    "    if cfg.generation.constraints:\n",
    "        # Strip (tab-delimited) contraints, if present, from input lines,\n",
    "        # store them in batch_constraints\n",
    "        batch_constraints = [list() for _ in lines]\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"\\t\" in line:\n",
    "                lines[i], *batch_constraints[i] = line.split(\"\\t\")\n",
    "\n",
    "        # Convert each List[str] to List[Tensor]\n",
    "        for i, constraint_list in enumerate(batch_constraints):\n",
    "            batch_constraints[i] = [\n",
    "                task.target_dictionary.encode_line(\n",
    "                    encode_fn_target(constraint),\n",
    "                    append_eos=False,\n",
    "                    add_if_not_exist=False,\n",
    "                )\n",
    "                for constraint in constraint_list\n",
    "            ]\n",
    "\n",
    "    if cfg.generation.constraints:\n",
    "        constraints_tensor = pack_constraints(batch_constraints)\n",
    "    else:\n",
    "        constraints_tensor = None\n",
    "\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    if os.path.exists('data/sentencepiece.bpe.model'):\n",
    "        tokenizer.Load('data/sentencepiece.bpe.model')\n",
    "    else:\n",
    "        tokenizer = None\n",
    "    tokens, lengths, img_src_tokens, img_gpt_input_mask = get_interactive_tokens_and_lengths(task, lines, encode_fn, tokenizer)\n",
    "\n",
    "    itr = task.get_batch_iterator(\n",
    "        dataset=task.build_dataset_for_caption_inference(\n",
    "            tokens, lengths, img_src_tokens, img_gpt_input_mask, constraints=constraints_tensor\n",
    "        ),\n",
    "        max_tokens=cfg.dataset.max_tokens,\n",
    "        max_sentences=cfg.dataset.batch_size,\n",
    "        max_positions=max_positions,\n",
    "        ignore_invalid_inputs=cfg.dataset.skip_invalid_size_inputs_valid_test,\n",
    "    ).next_epoch_itr(shuffle=False)\n",
    "    for batch in itr:\n",
    "        ids = batch[\"id\"]\n",
    "        src_tokens = batch[\"net_input\"][\"src_tokens\"]\n",
    "        src_lengths = batch[\"net_input\"][\"src_lengths\"]\n",
    "        img_src_tokens = batch[\"net_input\"][\"img_src_tokens\"]\n",
    "        img_gpt_input_mask = batch[\"net_input\"][\"img_gpt_input_mask\"]\n",
    "        constraints = batch.get(\"constraints\", None)\n",
    "\n",
    "        yield Batch(\n",
    "            ids=ids,\n",
    "            src_tokens=src_tokens,\n",
    "            src_lengths=src_lengths,\n",
    "            img_src_tokens=img_src_tokens,\n",
    "            img_gpt_input_mask=img_gpt_input_mask,\n",
    "            constraints=constraints,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 15:05:43 | INFO | fairseq_cli.interactive | {'hydra': {'run': {'dir': '.'}}, 'defaults': ['_self_', {'task': {'_name': 'generation_obj', 'data': 'None', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': True, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': 1, 'batch_size_valid': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'required_batch_size_multiple': 1, 'dict_path': '/home/omote/WorkSpace/unilm/kosmos-2/data/dict.txt', 'image_feature_length': 64, 'input_resolution': 1024, 'location_bin_size': 32, 'locate_special_token': 1}}, {'model': None}, {'criterion': 'cross_entropy'}, {'optimizer': None}, {'lr_scheduler': 'fixed'}, {'bpe': None}, {'tokenizer': None}, {'scoring': None}, {'generation': None}, {'common_eval': {'path': '/home/omote/WorkSpace/unilm/kosmos-2/model_weights/kosmos2.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': \"{'visual_pretrained': '', 'dict_path':'data/dict.txt'}\"}}, {'eval_lm': None}]}\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load('../configs/config.yaml')\n",
    "\n",
    "if isinstance(cfg, Namespace):\n",
    "    cfg = convert_namespace_to_omegaconf(cfg)\n",
    "\n",
    "logger.info(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dict-path': 'data/dict.txt', 'required-batch-size-multiple': 1, 'remove-bpe': 'sentencepiece', 'max-len-b': 500, 'add-bos-token': True, 'beam': 1, 'buffer-size': 1, 'image-feature-length': 64, 'locate-special-token': 1, 'batch-size': 1, 'nbest': 1, 'no-repeat-ngram-size': 3, 'location-bin-size': 32}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.import_user_module(cfg.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hydra': {'run': {'dir': '.'}}, 'defaults': ['_self_', {'task': '_generation_obj'}, {'model': None}, {'criterion': 'cross_entropy'}, {'optimizer': None}, {'lr_scheduler': 'fixed'}, {'bpe': None}, {'tokenizer': None}, {'scoring': None}, {'generation': None}, {'common_eval': None}, {'eval_lm': None}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kosmos-2-LcC9r1mE-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
